#决策树算法
from math import log
def calcShannonEnt(dataset):#计算香农熵
   numEntries=len(dataset)
   labelCounts={}
   for featVec in dataset:
       currentLabel=featVec[-1]
       if currentLabel not in labelCounts.keys():
          labelCounts[currentLabel]=0
       labelCounts[currentLabel]+=1
   shannonEnt=0
   for key in labelCounts:   #labelcounts是键值对的健的集合
      prob=float(labelCounts[key])/numEntries
      shannonEnt-=prob*log(prob,2)
   return shannoEnt

def creatDataSet():
   dataSet=[[1,2,'yes'],
            [1,1,'yes'],
            [1,0,'no'],
            [0,1,'no'],
            [0,1,'no']]
  labels=['no surfacing','flippers']
  return dataSet,labels

def splitDataSet(dataset,axis,value):
    retDataSet=[]
    for featVec in dataset:
       if featVec[axis]==value:
         reduceFeatVec=featVec[:axis]   #其实这里是删除了axis列的数据并返回数据到retdataset
         reduceFeatVec.extend(featVec[axis+1:]
         retDataSet.append(reduceFeatVec)
    return retDataSet

def chooseBestFeatureToSpit(dataSet):
     numFeatures=len(dataSet[0])-1
     baseEntropy=calcShannonEnt(dataSet)
     bestInfoGain=0
     bestFeature=-1
